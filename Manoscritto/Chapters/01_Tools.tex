\chapter{Preliminary definitions, notation and tools}

In this chapter we will go through basic definitions and notation about tensors, introduce tensor unfoldings, see the most common tensor products and introduce the idea of tensor rank.

\section{Definitions and notation}

A \emph{tensor} is a multidimensional array. Following this simple definition, the elements of a tensor are indexed by several indices.
%%%More formally, a \N-order tensor is an element of the tensor product of \N vector spaces.
The idea of tensor generalizes those of \emph{matrix} and \emph{vector}, making it possible to naturally represent data having a multi-way origin.

\begin{Def}
  The \emph{order}, or number of \emph{ways} or \emph{modes}, of a tensor is its number of dimensions, i.e.\ its number of indices.
\end{Def}
So if we have a $d$-way tensor \A, we can refer to its elements as
\begin{equation*}
  \A(i_1,\ldots,i_d)
\end{equation*}
From this definition it\todo{Ask Laura if this form is correct} follows that vectors are tensors of order \emph{one} and matrices are tensors of order \emph{two}.

\begin{Def}
  The higher-order analogue of matrix rows and columns are called \emph{fibers}. The \emph{i-th fiber} of a tensor \A is the vector of elements given by fixing all the indices but the i-th.
\end{Def}

\begin{Def}
  Two-dimensional sections of a tensor are called \emph{slices}. A \emph{slice} is the matrix obtained by fixing all but two indices.
\end{Def}

\begin{Def}
  We can define the \emph{norm} of a tensor as a general form of the matrix Frobenius norm:
  \[
  \|\A\|_F = \sqrt{\sum_{i_1 = 1}^{I_1}\sum_{i_2 = 1}^{I_2}\cdots\sum_{i_d = 1}^{I_d}\A^2(i_1 i_2 \cdots i_d)}
  \]
\end{Def}

\todo{Vale la pena di aggiungere anche il prodotto scalare?}

%% \begin{Def}
%%   A $d$-way tensor \A is \emph{rank one} if it can be written as the outer product of $d$ vectors:
%%   \[
%%   \A = \vett{v^{(1)}} \circ \vett{v^{(2)}} \circ \cdots \circ \vett{v^{(d)}}
%%   \]
%%   This can be written elementwise as:
%%   \[
%%   \A(i_1,i_2,\cdots,i_d) = v_{i_1}^{(1)} v_{i_2}^{(2)} \cdots v_{i_d}^{(d)}
%%   \]
%% \end{Def}

\section{Unfoldings}
An important concept in the tensor world which will be heavily used in the tensor train decomposition is the operation of \emph{unfolding}\footnote{also called \emph{matricization} or \emph{flattening}}.

\emph{Unfolding} is the process of reordering the elements of a $d$-way tensor into a matrix. An \emph{unfolding matrix} of the tensor will be the result of this operation. Unfoldings can be performed using arbitrary algorithms, although some unfoldings show more useful properties than others.

In this work we will leverage the following unfolding:

\begin{Def}
  Let \A a $d$-way tensor. We define the \emph{k-th unfolding} matrix of \A as:
  \begin{equation} \label{def:unfolding}
    A_k = A_k(i_1,\dots,i_k;i_{k+1},\dots,i_d) = A(i_1,\dots,i_d)
  \end{equation}
where the first $k$ indices enumerate the rows of $A_k$, while the last $d - k$ indices enumerate the columns of $A_k$.
\end{Def}

\section{Rank-one tensor}
A $d$-way tensor \A is said to be \emph{rank-one} if it can be written as the outer product of \d vectors:
\begin{equation}
  \A = v^{(1)} \circ v^{(2)} \circ \cdots \circ v^{(d)}
\end{equation}
Elementwise this translates to:
\begin{equation}
  a_{i_1,i_2,\ldots,i_n} = v_{i_1}^{(1)} v_{i_2}^{(2)} \cdots v_{i_d}^{(d)}
\end{equation}
This can be seen as a generalization of the fact that
\begin{equation*}
  M = u v^t
\end{equation*}
is a rank-one matrix.

\section{Matrix Kronecker and Hadamard products}
\emph{Kronecker} and \emph{Hadamard} matrix products are important basic notations and they can be straighforwardly generalized to tensors. We now briefly define them as reference for the following chapters.
%\paragraph{Kronecker product}
\begin{Def}[Kronecker product]
  Let $A$ an $I \times J$ and $B$ a $K \times L$ matrices, their Kronecker product $A \otimes B$ is defined by
  \begin{equation} \label{def:kronecker}
    A \otimes B =
    \begin{bmatrix}
      a_{11}B & a_{12}B & \cdots & a_{1J}B \\
      a_{21}B & a_{22}B & \cdots & a_{2J}B \\
      \vdots & \vdots & \ddots & \cdots \\
      a_{I1}B & a_{I2}B & \cdots & a_{IJ}B
    \end{bmatrix}
  \end{equation}
\end{Def}
The result of the Kronecker product is thus an $IK \times JL$ matrix obtained by multiplying each element of $A$ by the entire matrix $B$.

%\paragraph{Hadamard product}
\begin{Def}[Hadamard product]
  The Hadamard product is the elementwise matrix product. If $A$ and $B$ are both $I \times J$ matrices, their Hadamard product $A \circ B$ is defined by
  \begin{equation} \label{def:hadamard}
    A \circ B =
    \begin{bmatrix}
      a_{11}b_{11} & a_{12}b_{12} & \cdots & a_{1J}b_{1J} \\
      a_{21}b_{21} & a_{22}b_{22} & \cdots & a_{2J}b_{2J} \\
      \vdots & \vdots & \ddots & \cdots \\
      a_{I1}b_{I1} & a_{I2}b_{I2} & \cdots & a_{IJ}b_{IJ}
    \end{bmatrix}
  \end{equation}
\end{Def}

\section{Tensor-by-matrix product}
We can define a tensor-by-matrix product in several ways. In this work we will always refer to \e{mode-k contraction} or \e{mode-k multiplication}.\todo{Forse si pu√≤ omettere?}

\begin{Def} \label{def:tensor-matrix-product}
  Given a $d$-way tensor $\A \in I_1 \times \cdots \times I_d$ with elements $\A(i_1,\ldots,i_d)$ and a matrix $U \in I_\alpha \times I_k$ with elements $U(\alpha,i_k)$, we define the \e{mode-k multiplication}
  \begin{equation*}
    \A \times_k U
  \end{equation*}
  as the contraction over the $k$-th axis\footnote{$\alpha$ is on the $k$-th place.}, yielding a tensor $\B \in I_1 \times \cdots \times I_\alpha \times \cdots \times I_d$ as follows
  \begin{equation*}
    \A \times_k U = B(i_1,\ldots,\alpha,\ldots,i_d) = \sum_{i_k = 1}^{n_k} A(i_1,\ldots,i_k,\ldots,i_d) U(\alpha,i_k)
  \end{equation*}
\end{Def}
This can be seen as performing the product of each mode-$k$ fiber by the matrix $U$.

