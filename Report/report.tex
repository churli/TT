\documentclass[11pt,a4paper]{article}
%\documentclass[11pt,a4paper,draft]{book}

%%% Packages
\usepackage{Styles/reportstyle}
%\usepackage{Styles/unipitesi}
\usepackage{Styles/commands}

\usepackage{amsfonts}
\lstset{language=Python}
%%%
\title{Immagini animate e Tensor Train.\\Compressione e suoi effetti su dati visibili.}
\author{Tommaso Bianucci}
%%%
\begin{document}
\maketitle

%% \begin{abstract}
%%   La \emph{Tensor Train Decomposition} (\emph{TT}), è un formato di rappresentazione di tensori di recente sviluppo che ha come principale obiettivo quello di fornire una buona approssimazione del tensore iniziale utilizzando un numero ridotto di \emph{parametri}, analogamente a quanto la \emph{Singular Value Decomposition} (\emph{SVD}) permette di fare con le matrici.

%%   %% In particolare, questo metodo di rappresentazione \emph{rompe} la diendenza esponenziale dal numero di dimensioni, rendendo finalmente possibili applicazioni con alta dimensionalità.
%%   %% Per questo possiamo riferirci alla TT come strumento di \emph{compressione} di dati, in quanto permette di manipolare dati dalla elevata dimensionalità con un'impronta in memoria relativamente ridotta.

%%   La qualità della rappresentazione è stata definita e dimostrata da risultati teorici, ma cosa questa comporti a livello qualitativo sui dati in ingresso resta difficile da immaginare, complicato inoltre dalla intrinseca difficoltà di rappresentazione di dati a più di 3 dimensioni.

%%   La compressione di immagini è un classico esempio che permette di apprezzare immediatamente il risultato della SVD, così abbiamo utilizzato un approccio analogo con la TT, comprimendo brevi animazioni.
%%   Le immagini animate costituiscono infatti un facile esempio di dato in 4 dimensioni: larghezza, altezza, colore e numero di frame.
%%   Abbiamo quindi compresso le animazioni in formato TT, misurato il \emph{rapporto di compressione} e ricostruito le animazioni approssimate per un facile confronto visivo con l'originale. \todo{Rivedi, anche alla luce di quanto riutilizzato sotto in Obiettivi}
%% \end{abstract}

%\listoftodos
\tableofcontents

%%% WRITE TEXT HERE
\section{Obiettivi}
La \emph{Tensor Train Decomposition}, o più brevemente \emph{TT}, è un formato di rappresentazione di tensori\footnote{Con tensore intendiamo genericamente un array multidimensionale.} di recente sviluppo che ha come principale obiettivo quello di fornire una buona approssimazione del tensore iniziale utilizzando un numero ridotto di \emph{parametri}, analogamente a quanto la \emph{Singular Value Decomposition (SVD)} permette di fare con le matrici.
In particolare, questo metodo di rappresentazione \emph{rompe} la dipendenza esponenziale dal numero di dimensioni, rendendo finalmente possibili applicazioni con alta dimensionalità.
Per questo possiamo riferirci alla TT come strumento di \emph{compressione} di dati, in quanto permette di manipolare dati dalla elevata dimensionalità con un'impronta in memoria relativamente ridotta.

  La qualità della rappresentazione è stata definita e dimostrata da risultati teorici, ma cosa questa comporti a livello qualitativo sui dati in ingresso resta difficile da immaginare, complicato inoltre dalla intrinseca difficoltà di rappresentazione di dati a più di 3 dimensioni.

  La compressione di immagini è un classico esempio che permette di visualizzare il risultato della SVD, apprezzandone intuitivamente le caratteristiche principali. Così abbiamo pensato di seguire un approccio analogo con la TT: comprimere immagini per poterne visualizzare immediatamente il risultato.

  Ci siamo quindi posti l'obiettivo di comprimere le animazioni in formato TT, misure alcuni parametri della compressione e ricostruire le animazioni approssimate per un facile confronto visivo con l'originale.

\section{Approccio}
Un tensore rappresentato in formato TT consta di un insieme di tensori 3-dimensionali i cui elementi, opportunamente moltiplicati tra di loro, restituiscono tutti gli elementi, entro un certo grado di approssimazione, del tensore di partenza.
Questo lascia intuire come i vantaggi del formato TT siano tanto maggiori quanto maggiore è la dimensionalità del tensore originario.
Inoltre possiamo notare come i benefici su tensori 3-dimensionali siano esigui, se non assenti da un punto di vista di spazio utilizzato e vanificati dalla complessità e dal tempo computazionale aggiuntivi che la rappresentazione in formato TT richiede.

Con questa premessa abbiamo cercato una tipologia di dati che avesse un numero di dimensioni maggiore di 3 e che fosse facilmente visualizzabile. Per questo abbiamo scelto di applicare il formato TT a delle immagini animate.

Le sequenze animate sono infatti naturalmente rappresentabili in 4 dimensioni, infatti:
\begin{itemize}
\item sono certamente un insieme ordinato di immagini (\emph{frame}),
\item ogni frame è composto da una matrice di \emph{pixel},
\item ogni pixel può emettere i 3 colori primari (RGB\footnote{\emph{RGB} = red-green-blue (rosso-verde-blu), i tre colori primari per la sintesi sottrattiva.}), ognuno caratterizzato da un proprio valore di luminosità.
\end{itemize}
In 4 dimensioni si strutturano quindi i dati di una sequenza animata: numero di frame (per identificare la posizione temporale), larghezza e altezza (per identificare la posizione spaziale del pixel) e colore. Gli elementi del tensore assumeranno quindi valori tra $0$ e $255$ e rappresenteranno la luminosità di un dato colore per un certo pixel all'interno di uno specifico frame.

\section{Implementazione, problemi e compromessi}
Per l'implementazione abbiamo utilizzato il seguente approccio:
\begin{itemize}
\item estrarre i singoli frame dalle animazioni GIF in ingresso e convertirli in formato PPM utilizzando il comando \rawcode{convert} dalla suite \href{http://www.imagemagick.org/}{Imagemagick},
\item leggere i frame per popolare gli elementi di un tensore di dimensioni adeguate,
\item approssimare iterativamente il tensore utilizzando l'algoritmo \emph{tt-cross} dalla libreria \href{https://github.com/oseledets/ttpy}{\emph{ttpy}} di Ivan Oseledets,
\item estrarre i valori per ogni frame e scriverli in un nuovo file PPM,
\item infine ricomporre i file PPM risultanti in una nuova animazione GIF.
\end{itemize}

\subsection{Linguaggi utilizzati}
Le operazioni di estrazione, conversione a PPM e ricomposizione dei frame dal o verso il formato GIF sono state organizzate sotto forma di brevi script in \emph{Bash}. Invece la parte saliente di lettura dei frame, approssimazione in formato TT e riscrittura dei nuovi frame è stata implementata in linguaggio \emph{Python}. Ulteriori dettagli, insieme al codice completo, sono disponibili in appendice \ref{code:all}.

La scelta di utilizzare Python è risultata dal considerare che:
\begin{itemize}
\item Python è un linguaggio flessibile e agevole, tipizzato dinamicamente e che non richiede una gestione manuale dell'allocazione di memoria, rendendo la prototipazione e cambiamenti anche radicali molto agevoli e veloci,
\item è disponibile, per Python, il modulo \emph{ttpy}, che implementa la rappresentazione e i vari algoritmi per la compressione e la manipolazione di tensori in formato TT,
\item Python è un linguaggio notoriamente poco performante, ma il modulo \emph{ttpy} implementa tutte le operazioni computazionalmente intense e critiche in linguaggio Fortran, avvalendosi dove possibile di subroutine da LaPack/BLAS.
\end{itemize}
In questo modo è stato possibile mantenere i vantaggi di un linguaggio come Python, pur conservando tutte le fasi computazionalmente più costose in opportune subroutine Fortran e quindi non intaccando le prestazioni complessive dell'intero processo.

\subsection{TT-cross e criteri d'arresto}
\paragraph{TT-cross.}
L'algoritmo di TT-cross è basato sull'approssimazione iterativa di un tensore tramite l'utilizzo, ad ogni passo, di alcuni specifici elementi.
Questo permette la costruzione di un un'approssimazione TT anche in assenza del tensore completo di partenza. Infatti è sufficiente avere a disposizione una funzione che permetta di calcolare, date le coordinate di un elemento, il suo valore.

Costruiamo esplicitamente l'intero tensore di partenza, popolandolo con i valori che vengono letti dai file che contengono i vari frame: in questo caso lo spazio richiesto da questa operazione è davvero modesto e ci avvantaggia in termini di tempo. Abbiamo comunque definito una funzione che ci restituisce l'elemento del tensore date le coordinate, in modo da poterla utilizzare nell'algoritmo TT-cross.

\paragraph{Misurare l'errore.}
Per decidere quando arrestare l'iterazione, abbiamo bisogno di definire una misura di errore.

Per il nostro scopo di comprimere animazioni abbiamo deciso di affidarci ad un metodo molto semplice ma che ha dimostrato di dare buoni risultati: vengono campionati casualmente l'1\% degli elementi del tensore e calcolata la distanza dal corrispondente valore del tensore originario; se l'elemento è all'interno di un raggio di 5 unità di luminosità dal corrispondente valore del tensore originario viene considerato valido, altrimenti non valido.
La percentuale di valori validi sul totale campionato è utilizzata come parametro indice della verosimiglianza dell'animazione compressa rispetto all'originale.

La scelta è caduta su questo criterio, a dire il vero piuttosto \emph{artigianale}, dopo aver osservato che l'errore relativo, così come misurato internamente durante l'algoritmo di TT-cross, convergeva troppo lentamente e a valori non generalizzabili ai vari esempi di input provati, sebbene i risultati in uscita fossero sufficientemente accurati da un punto di vista visivo.

\paragraph{Criteri d'arresto.}
Come menzionato nel precedente paragrafo, per questa applicazione ci siamo affidati ad un criterio d'arresto \emph{ad-hoc}: quando una percentuale sufficientemente alta di elementi presenta un errore al di sotto di un certo valore, l'approssimazione viene fermata.

Come intuibile, questo criterio presenta il grande difetto di non tenere in considerazione quanto errore presentino gli elementi che non hanno superato il test.
D'altra parte però questo criterio ci permette di terminare le iterazioni non appena una parte sufficiente dell'animazione approssima bene l'originale.

Questa scelta del tutto arbitraria e volta a contenere i tempi di convergenza ed il numero di parametri necessario, lascia passare nelle immagini finali alcuni artefatti degni di nota. Ad esempio può portare alcune parti dell'immagine ad avere valori di colore/luminosità molto instabili nel tempo, mentre altre parti risultano ben definite. Oppure si possono avere parti dell'immagine che ricompaiono come \emph{fantasmi} in frame multipli.\footnote{A questo proposito è bene ricordare come il \emph{tempo} altro non sia che una dimensione del tensore al pari delle altre e quindi presenti artefatti al pari delle dimensioni \emph{spaziali}. Quindi medesimi valori possono propagrsi all'interno dello stesso frame, sotto forma di \emph{bande} orizzontali o verticali, ma anche attraverso più frame, sotto forma di zone di immagine \emph{fantasma}.}

\newpage

\subsection{Ottimizzazione delle performance}
In una prima implementazione, abbiamo osservato come la maggior parte del tempo veniva spesa nella fase di scrittura dei frame invece che in quella di TT-cross.
Questo succedeva a causa del seguente codice: 

\begin{lstlisting}
  for row in range(height):
      rowput = [ str(pixelRound(x, maxval=depth)) + " " for x in 
                      frame[:,:,row]
                      .full()
                      .reshape(3*width, order='F') ]
      f.writelines(rowput)
      f.write('\n')
\end{lstlisting}

Questo costruiva una riga del frame corrente prendendo, in formato TT, la matrice $3 \times width$ corrispondente alla riga, calcolandone tutti gli elementi (con il metodo \rawcode{full()}) e facendo quindi un reshape per ottenere la concatenazione dei valori di colore per ogni pixel.

Ci sono principalmente due motivi per cui questo era inefficiente.
Il primo è che il metodo \rawcode{full()} è computazionalmente molto costoso, in quanto implica $\prod_{j=1}^d n_j (d-1)$ moltiplicazioni di matrici per un tensore $n_1 \times \ldots \times n_d$. Nel nostro caso questa operazione comportava, per ogni riga, $2 \cdot 3 \cdot width$ moltiplicazioni di matrici, per un totale di $6 \cdot width \cdot height$ moltiplicazioni di matrici per frame, visto che l'operazione veniva eseguita in un ciclo indicizzato dal numero di riga. Il problema è che una buona parte di queste moltiplicazioni è ridondante: infatti quando si fissano tutti gli elementi di un tensore tranne uno, tutte le matrici da moltiplicare resteranno invariate tranne quella corrispondente alla dimensione su cui scorre quest'ultimo. Per ottenere tutti gli elementi di una data \emph{fibra} del tensore, ad esempio sulla dimensione $k$, dobbiamo quindi calcolare $n_k (d-1)$ moltiplicazioni di matrici, quando ne sarebbero necessarie soltanto $(d-2) + n_k$.

Il secondo motivo di inefficienza risiede nell'uso del metodo \rawcode{reshape()}: infatti \rawcode{full()} calcola tutti gli elementi del dato tensore in modo sequenziale, restituendoli in un array monodimensionale e applicando poi l'opportuno reshape per ottenere il tensore. Il problema è che nel nostro codice abbiamo bisogno di applicare un ulteriore \rawcode{reshape(3*width, order='F')}, di fatto rendendo il primo superfluo.

Abbiamo risolto il primo problema calcolandoci tutti i valori di un intero frame con una sola chiamata di \rawcode{full}, invece che farne una per ogni riga. Infatti, con un opportuna manipolazione possiamo ottenere una lista di righe da poter scrivere nel file, senza dover iterare sulle righe come in precedenza. Questo risolve problema in quanto il metodo \rawcode{full()} è in grado di ottimizzare il numero di moltiplicazioni di matrici da eseguire.

Il secondo problema è invece stato risolto cambiando il metodo \rawcode{full()} nella libreria \emph{ttpy} in modo da poter accettare come argomento opzionale uno \emph{shape} specifico da passare alla chiamata di \rawcode{reshape()} che esegue internamente. Questo evita il bisogno di chiamare ogni volta un secondo \rawcode{reshape()} per ottenere il formato desiderato.

Il risultato è il seguente codice, che restituisce una lista di righe, che vengono successivamente scritte del file per il frame corrente:
\begin{lstlisting}
    frameput = [ ' '.join(vectorStrPixelRound(x)) for x in 
                    (depth*frame)
                    .full(shape=(3*width,height))
                    .transpose() ]
    for row in range(height):
        f.write(frameput[row])
        f.write('\n')
\end{lstlisting}

Queste piccole modifiche hanno ridotto il tempo dedicato alla scrittura dei frame su file dall'ordine di alcune ore all'ordine di pochi minuti.

%% \paragraph{Lettura frame.}
%% foobar ciao

%% \paragraph{Scrittura frame.}
%% foobar

%% \paragraph{Modifiche \emph{ad-hoc} del modulo ttpy.}
%% foobar

\section{Risultati}
Da un punto di vista di rapporto di compressione non abbiamo ottenuto risultati degni di nota (vedi tabella \ref{tab:results}) e questo è in linea con le aspettative. Infatti il vantaggio del formato TT sta nel disaccopiare il numero di parametri necessari dalla dipendenza esponenziale dal numero di dimensioni; non ci aspettavamo di vedere risultati rilevanti con sole 4 dimensioni.
\begin{center}
  \begin{tabular}[t]{| c | c | c | c | c | c |}
    \hline
    &GameBoy&Cats&67P&MuhammadAli&PikachuSurf\\
    \hline
    Sweeps&24&14&34&50&16\\
    Wall Time&00:05:42&00:03:42&00:31:56&02:26:44&00:03:35\\
    CPU Time&00:09:55&00:16:28&02:28:21&15:15:18&00:14:26\\
    Passrate&50\%&51\%&52\%&50\%&55\%\\
    Size Full&10\,500\,000&34\,493\,760&37\,096\,800&84\,588\,840&15\,498\,000\\
    Size TT&4\,671\,736&4\,584\,860&19\,374\,766&33\,603\,020&7\,278\,045\\
    Size Ratio&0.44&0.13&0.52&0.40&0.47\\
    \hline
    Original&
    \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/game_boy.gif}{link}&
    \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/cats.gif}{link}&
    \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/67P.gif}{link}&
    \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/muhammad_ali.gif}{link}&
    \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/pikachu_surf.gif}{link}\\
    Compressed&
    \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/game_boy_TT.gif}{link\_TT}&
    \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/cats_TT.gif}{link\_TT}&
    \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/67P_TT.gif}{link\_TT}&
    \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/muhammad_ali_TT.gif}{link\_TT}&
    \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/pikachu_surf_TT.gif}{link\_TT}\\
    \hline
  \end{tabular}
  \captionof{table}{\label{tab:results}Risultati computazionali. \emph{Sweeps} sono le iterazioni compiute dall'algoritmo TT-cross. I tempi sono espressi in formato hh:mm:ss, le dimensioni in numero di elementi.}
\end{center}

Da un punto di vista qualitativo abbiamo potuto rilevare la presenza di artefatti quali la propagazione di \emph{rumore} lungo le fibre del tensore e improvvisi cambi di luminosità e colore.

La fase di calcolo della compressione ha mostrato una convergenza assai lenta, soprattutto se paragonata alla convergenza che l'algoritmo di TT-cross ha dimostrato in alcuni esempi di natura matematica, come nel caso di tensori popolati con i valori assunti da una funzione multidimensionale. In particolare, è stato impossibile stabilire valori di errore relativo in norma che potessero essere utilizzati in maniera affidabile e con una certa generalità. Al contrario, la semplice misura dell'errore da noi utilizzata si è rivelata utile ad avere un'approssimazione in ogni caso accettabile.

Vediamo alcuni esempi di questi artefatti. La sequenza~\ref{fig:cats_sequence_phantoms} mostra tre frame consecutivi dall'animazione \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/cats_TT.gif}{\rawcode{cats_TT.gif}} (originale \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/cats.gif}{\rawcode{cats.gif}}): possiamo chiaramente vedere degli elementi \emph{fantasma} nella zona in basso a destra dell'immagine. Questi elementi provengono da frame successivi, visibili in figura \ref{fig:cats_sequence_phantoms_comp}. Sono ben visibili elementi di tutti e tre questi frame nella sequenza originale.

\begin{figure}
  \captionsetup[subfigure]{justification=centering}
  \centering
  \def\wid{0.48}
  \def\scal{0.44}
  \begin{subfigure}[]{\wid\textwidth}
    \begin{subfigure}[]{\wid\textwidth}
      \centering
      \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/Cats/frame-10}
    \end{subfigure}
    
    \begin{subfigure}[]{\wid\textwidth}
      \centering
      \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/Cats/frame-11}
    \end{subfigure}
    
    \begin{subfigure}[]{\wid\textwidth}
      \centering
      \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/Cats/frame-12}
    \end{subfigure}
    \caption{Sequenza con elementi fantasma.}\label{fig:cats_sequence_phantoms}
  \end{subfigure}
  ~
  \begin{subfigure}[]{\wid\textwidth}
    \begin{subfigure}[]{\wid\textwidth}
      \centering
      \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/Cats/frame-105}
    \end{subfigure}
    
    \begin{subfigure}[]{\wid\textwidth}
      \centering
      \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/Cats/frame-111}
    \end{subfigure}
    
    \begin{subfigure}[]{\wid\textwidth}
      \centering
      \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/Cats/frame-113}
    \end{subfigure}
    \caption{Frame di provenienza.}\label{fig:cats_sequence_phantoms_comp}
  \end{subfigure}
  \caption{Elementi fantasma e rispettivi frame di provenienza.}
\end{figure}

\begin{figure}
  \def\wid{0.48}
  \def\scal{0.44}
  \captionsetup[subfigure]{justification=centering}
  \begin{subfigure}[]{\wid\textwidth}
    \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/Cats/frame-62}
    \caption{Frange di rumore che si propagano verticalmente rispetto ai gatti.}\label{fig:cats_noise_vertical}
  \end{subfigure}
  ~
  \begin{subfigure}[]{\wid\textwidth}
    \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/Cats/frame-94}
    \caption{Immagine fantasma sul lato destro dell'immagine}\label{fig:cats_noise_time}
  \end{subfigure}
  \caption{Propagazione di rumore e fantasmi lungo le fibre.}\label{fig:cats_noise}
\end{figure}

Ancora possiamo vedere, in figura \ref{fig:cats_noise}, come il rumore si propaghi lungo le fibre, rivelando la struttura stessa del formato TT: in figura \ref{fig:cats_noise_vertical} possiamo vedere come le sagome dei due gatti diano origine ad alcune bande verticali di pixel più scuri, mentre in figura \ref{fig:cats_noise_time} si veda in basso a destra la propagazione nella dimensione temporale di una sagoma proveniente da un altro frame.

Nell'animazione \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/muhammad_ali_TT.gif}{\rawcode{muhammad_ali_TT.gif}} (originale \href{http://poisson.phc.unipi.it/~bianucci/shared/tesi/muhammad_ali.gif}{\rawcode{muhammad_ali.gif}}) invece si possono vedere dei forti effetti di aberrazione cromatica, probabilmente a causa delle ampie zone molto scure che compongono l'immagine. In questo caso (figura \ref{fig:muhammadali_color_flickering}) possiamo vedere come in frame consecutivi ci sia una forte alternanza di luminosità e di colore, che nell'animazione provocano dei forti \emph{flash}.

\def\wid{0.48}
\def\scal{0.55}
\begin{figure}
  \captionsetup[subfigure]{justification=centering}
  \centering
  \begin{subfigure}[]{\wid\textwidth}
    \begin{subfigure}[]{\wid\textwidth}
      \centering
      \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/MuhammadAli/frame-11}
    \end{subfigure}
    
    \begin{subfigure}[]{\wid\textwidth}
      \centering
      \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/MuhammadAli/frame-12}
    \end{subfigure}
    \caption{Frame 11-12.}
  \end{subfigure}
  ~
  \begin{subfigure}[]{\wid\textwidth}
    \begin{subfigure}[]{\wid\textwidth}
      \centering
      \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/MuhammadAli/frame-208}
    \end{subfigure}
    
    \begin{subfigure}[]{\wid\textwidth}
      \centering
      \includegraphics[keepaspectratio=true, scale=\scal]{Imgs/MuhammadAli/frame-209}
    \end{subfigure}
    \caption{Frame 208-209.}
  \end{subfigure}
  \caption{Fluttuazioni cromatiche tra frame consecutivi.}\label{fig:muhammadali_color_flickering}
\end{figure}

\section{Conclusioni}
Abbiamo raggiunto il nostro scopo di \emph{visualizzare} gli effetti dell'approssimazione tramite TT. Certamente la qualità dell'immagine, la presenza di vistosi artefatti e lo scarso livello di compressione ci mostrano come la compressione di filmati non sia il campo di applicazione di elezione del formato TT.
Dobbiamo però ricordare come il basso numero di dimensioni (4) e il vincolo di dover rappresentare valori in $[0,255]\subset\NN$ limitino l'efficacia dell'utilizzo del formato TT in questa applicazione.

\newpage

\appendix
\section{Codice}\label{code:all}
Alleghiamo qui il codice dei vari script sviluppati e usati per la sperimentazione:
\begin{itemize}
\item \rawcode{ttgif.sh} (\ref{code:ttgif})
\item \rawcode{extractFrames.sh} (\ref{code:extractFrames})
\item \rawcode{imageCompress.py} (\ref{code:imageCompress})
\item \rawcode{reMergeFrames.sh} (\ref{code:reMergeFrames})
\item \rawcode{timing.py} (\ref{code:timing})
\end{itemize}

L'intero processo è gestito da \rawcode{ttgif.sh} che a sua volta esegue opportunamente le tre fasi principali di estrazione dei singoli frame dalla GIF iniziale (\rawcode{extractFrames.sh}), rappresentazione del tensore in formato TT (\rawcode{imageCompress.py}) e ricostruzione dell'animazione a partire dai frame approssimati al passo precedente (\rawcode{reMergeFrames}).

Il modulo \rawcode{timing.py} invece gestisce la misura dei tempi di calcolo ed il loro logging. È utilizzato da \rawcode{imageCompress.py}.

\newpage
%Codechange: 6
\def\coderepo{/home/tommaso/Repo/TTGif}
\subsection{ttgif.sh}\label{code:ttgif}
Questo script mette insieme le fasi fondamentali del processo e passa gli opportuni parametri a \rawcode{extractFrames.sh}, \rawcode{imageCompress.py} e \rawcode{reMergeFrames}.

\lstinputlisting[language=Bash,frame=L,numbers=left,title=\rawcode{ttgif.sh}]{\coderepo/ttgif.sh}
\newpage
\subsection{extractFrames.sh}\label{code:extractFrames}
Questo script utilizza \rawcode{convert} per estrarre i singoli frame dalla GIF in ingresso e per convertirli in formato PPM.

\lstinputlisting[language=Bash,frame=L,numbers=left,title=\rawcode{extractFrames.sh}]{\coderepo/extractFrames.sh}
\newpage
\subsection{imageCompress.sh}\label{code:imageCompress}
Questo script legge i singoli frame dell'animazione in ingresso e rappresenta il tensore risultante in formato TT. Infine restituisce i frame approssimati.

In particolare \rawcode{imageCompress.py} popola inizialmente il tensore completo e poi lo approssima iterativamente in formato TT utilizzando l'algoritmo \emph{TT-cross} all'interno della funzione \rawcode{dynCross()}.

Le funzioni \rawcode{readFrame()} e \rawcode{writeFrame()} si occupano rispettivamente della lettura e scrittura dei frame. La funzione \rawcode{strPixelRound()} e il suo corrispettivo vettoriale \rawcode{vectorStrPixelRound()} servono per \emph{appiattire} i valori in output sull'intervallo $[0,255]$ in modo da soddisfare il formato PPM.

Le dimensioni dei frame in ingresso sono dedotte utilizzando \rawcode{framesParametersCheck()}, mentre \rawcode{testRandomElement()} e \rawcode{testApproximation} si occupano di valutare l'\emph{errore} dell'approssimazione.

\lstinputlisting[language=Python,frame=L,numbers=left,title=\rawcode{imageCompress.py}]{\coderepo/imageCompress.py}
\newpage
\subsection{reMergeFrames.sh}\label{code:reMergeFrames}
Questo script utilizza \rawcode{convert} per unire i frame PPM in uscita dalla rappresentazione TT in una nuova animazione GIF.

\lstinputlisting[language=Bash,frame=L,numbers=left,title=\rawcode{reMergeFrames.sh}]{\coderepo/reMergeFrames.sh}
\newpage
\subsection{timing.py}\label{code:timing}
Questo script calcola il tempo reale e il tempo CPU del processo tra due eventi e ne gestisce il logging.

\lstinputlisting[language=Python,frame=L,numbers=left,title=\rawcode{timing.py}]{\coderepo/timing.py}
%%%
\end{document}
